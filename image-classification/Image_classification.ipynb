{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Data pre-processing and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fded31cd940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open(\"data/testing/2/477.jpg\")\n",
    "im = np.array(im)\n",
    "print(\"Image Shape:\", im.shape)\n",
    "plt.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255, # is a value by which we will multiply the data before any other processing\n",
    "                                  shear_range=0.2, #is for randomly applying shearing transformations\n",
    "                                  zoom_range=0.2, #is for randomly zooming inside pictures\n",
    "                                  horizontal_flip=True, #is for randomly flipping half of the images horizontally\n",
    "                                  rotation_range=40, #is a value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "                                  width_shift_range=0.2, #which to randomly translate pictures vertically or horizontally\n",
    "                                  height_shift_range=0.2, \n",
    "                                  fill_mode='nearest' #is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
    "                                 )\n",
    "\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\"data/testing\", batch_size=1, \n",
    "                                                        class_mode='categorical', \n",
    "                                                        color_mode='grayscale', \n",
    "                                                        target_size=(28,28)\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in validation_generator:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    plt.imshow(x[0,:,:,0], cmap='gray')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictclass = validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictclass['5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Object Oriented Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Classifier():\n",
    "    def __init__(self, train_folder='data/train', validation_folder='data/validation', \n",
    "                  inshape=(28,28,1), num_classes=10, num_train=1000, num_validation=200):\n",
    "        self.train_folder = train_folder\n",
    "        self.validation_folder =  validation_folder\n",
    "        self.inshape = inshape\n",
    "    \n",
    "        self.num_classes = num_classes\n",
    "        self.num_train = num_train\n",
    "        self.num_validation = num_validation\n",
    "        \n",
    "    def model(self, inshape=(28,28,1), num_classes=10, learning_rate=0.001):\n",
    "        '''\n",
    "            Three steps to Convolution\n",
    "                1. Convolution\n",
    "                2. Activation\n",
    "                3. Polling\n",
    "            Repeat Steps 1,2,3 for adding more hidden layers\n",
    "                4. After that make a fully connected network\n",
    "            This fully connected network gives ability to the CNN\n",
    "            to classify the samples\n",
    "        '''\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu', \n",
    "                         kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "                         input_shape=inshape, data_format=\"channels_last\"))\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "        model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu', \n",
    "                         kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
    "\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "    \n",
    "        model.add(Dropout(rate=0.8)) # rate: rate of nodes to be keeped\n",
    "\n",
    "        model.add(Dense(units=512, activation='relu'))\n",
    "        \n",
    "        model.add(Dropout(rate=0.8))\n",
    "\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        \n",
    "        # Binary cross-entropy is for multi-label classifications, whereas categorical cross entropy is for multi-class classification where each example belongs to a single class.\n",
    "        optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, batch_size=128, epochs=12, learning_rate=0.001, model_file=\"my_model.h5\", refine = False):\n",
    "        '''\n",
    "            Train Process\n",
    "        '''\n",
    "        # this is the augmentation configuration we will use for training\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255, # is a value by which we will multiply the data before any other processing\n",
    "                                            shear_range=0.2, #is for randomly applying shearing transformations\n",
    "                                            zoom_range=0.2, #is for randomly zooming inside pictures\n",
    "                                            horizontal_flip=True, #is for randomly flipping half of the images horizontally\n",
    "                                            #rotation_range=40, #is a value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "                                            #width_shift_range=0.2, #which to randomly translate pictures vertically or horizontally\n",
    "                                            #height_shift_range=0.2, \n",
    "                                            #fill_mode='nearest' #is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
    "                                          )\n",
    "\n",
    "        # this is the augmentation configuration we will use for testing:\n",
    "        # only rescaling\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        # this is a generator that will read pictures found in\n",
    "        # subfolers of 'data/train', and indefinitely generate\n",
    "        # batches of augmented image data\n",
    "        train_generator = train_datagen.flow_from_directory(self.train_folder,  # this is the target directory\n",
    "                                                            target_size=(28,28),  # all images will be resized to 150x150\n",
    "                                                            batch_size=batch_size, \n",
    "                                                            color_mode='grayscale',\n",
    "                                                            #class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "                                                           )\n",
    "        # this is a similar generator, for validation data\n",
    "        validation_generator = test_datagen.flow_from_directory(self.validation_folder, \n",
    "                                                                target_size=(28,28),\n",
    "                                                                batch_size=batch_size, \n",
    "                                                                color_mode='grayscale',\n",
    "                                                                #class_mode='binary'\n",
    "                                                               )\n",
    "        if refine:\n",
    "            model = load_model(model_file)\n",
    "        else:\n",
    "            model = self.model(inshape=self.inshape, num_classes=self.num_classes, learning_rate=learning_rate)\n",
    "        \n",
    "        ts = time.time()\n",
    "        tbCallBack = TensorBoard(log_dir='./logs/' + str(ts), histogram_freq=0, write_graph=True, write_images=True)\n",
    "        \n",
    "        # To launch tensorbord\n",
    "        # tensorboard --logdir ./logs\n",
    "        model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=self.num_train // batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=self.num_validation // batch_size,\n",
    "                            callbacks=[tbCallBack])\n",
    "        \n",
    "        # You can use model.save(filepath) to save a Keras model into a single HDF5 file which will contain:\n",
    "        # 1- the architecture of the model, allowing to re-create the model\n",
    "        # 2- the weights of the model\n",
    "        # 3- the training configuration (loss, optimizer)\n",
    "        # 4- the state of the optimizer, allowing to resume training exactly where you left off.\n",
    "\n",
    "        model.save(model_file)\n",
    "        \n",
    "        \n",
    "    def predict(self, x, model_file=\"my_model.h5\"):\n",
    "        model = load_model(model_file)\n",
    "        prediction = model.predict(x)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "WARNING:tensorflow:From /media/DATA/miniconda/envs/edx/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /media/DATA/miniconda/envs/edx/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /media/DATA/miniconda/envs/edx/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/12\n",
      "468/468 [==============================] - 63s 135ms/step - loss: 1.1064 - acc: 0.6216 - val_loss: 0.3265 - val_acc: 0.9018\n",
      "Epoch 2/12\n",
      "468/468 [==============================] - 62s 133ms/step - loss: 0.6968 - acc: 0.7677 - val_loss: 0.2584 - val_acc: 0.9330\n",
      "Epoch 3/12\n",
      "468/468 [==============================] - 60s 128ms/step - loss: 0.6052 - acc: 0.8015 - val_loss: 0.1969 - val_acc: 0.9397\n",
      "Epoch 4/12\n",
      "468/468 [==============================] - 61s 129ms/step - loss: 0.5359 - acc: 0.8274 - val_loss: 0.1996 - val_acc: 0.9442\n",
      "Epoch 5/12\n",
      "468/468 [==============================] - 62s 132ms/step - loss: 0.4928 - acc: 0.8434 - val_loss: 0.1400 - val_acc: 0.9621\n",
      "Epoch 6/12\n",
      "468/468 [==============================] - 64s 137ms/step - loss: 0.4637 - acc: 0.8525 - val_loss: 0.1217 - val_acc: 0.9598\n",
      "Epoch 7/12\n",
      "468/468 [==============================] - 64s 136ms/step - loss: 0.4240 - acc: 0.8652 - val_loss: 0.1180 - val_acc: 0.9632\n",
      "Epoch 8/12\n",
      "468/468 [==============================] - 61s 131ms/step - loss: 0.4129 - acc: 0.8700 - val_loss: 0.0886 - val_acc: 0.9732\n",
      "Epoch 9/12\n",
      "468/468 [==============================] - 65s 139ms/step - loss: 0.3979 - acc: 0.8757 - val_loss: 0.1163 - val_acc: 0.9676\n",
      "Epoch 10/12\n",
      "468/468 [==============================] - 66s 141ms/step - loss: 0.3772 - acc: 0.8824 - val_loss: 0.0869 - val_acc: 0.9732\n",
      "Epoch 11/12\n",
      "468/468 [==============================] - 71s 152ms/step - loss: 0.3704 - acc: 0.8836 - val_loss: 0.0744 - val_acc: 0.9799\n",
      "Epoch 12/12\n",
      "468/468 [==============================] - 72s 153ms/step - loss: 0.3628 - acc: 0.8865 - val_loss: 0.0908 - val_acc: 0.9758\n"
     ]
    }
   ],
   "source": [
    "im_classifier = Image_Classifier(train_folder = 'data/training', \n",
    "                                 validation_folder = 'data/testing', \n",
    "                                 inshape=(28,28,1), num_classes=10,\n",
    "                                 num_train=60000, num_validation=1000)\n",
    "\n",
    "im_classifier.train(batch_size=128, epochs=12, learning_rate=0.001)\n",
    "# im_classifier.train(batch_size=128, epochs=20, learning_rate=0.0001, refine=True, model_file=\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Inference Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "The corresponding image digit is : 6\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"data/testing/6/870.jpg\")\n",
    "im = np.array(im)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = np.expand_dims(im, axis=3)\n",
    "print(im.shape)\n",
    "im_classifier = Image_Classifier()\n",
    "prediction = im_classifier.predict(im, model_file=\"my_model.h5\")\n",
    "prediction_digit = prediction[0].argmax()\n",
    "print(\"The corresponding image digit is :\", prediction_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fine-tuning the top layers of a pre-trained network (Transfert Learning)\n",
    "Fine-tuning consist in starting from a trained network, then re-training it on a new dataset using very small weight updates.\n",
    "* instantiate the convolutional base of the model and load its weights\n",
    "* add our defined fully-connected model on top, and load its weights\n",
    "* freeze the layers of the pretrained model up to the last convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "# base_model = InceptionV3(weights='imagenet') #, include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new model\n",
    "Now that we have set the trainable parameters of our base network, we would like to add a classifier on top of the convolutional base. We will simply add a fully connected layer followed by a softmax layer with 3 outputs. This is done as given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained model\n",
    "First, we will load a inception-v3 model without the top layer ( which consists of fully connected layers )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model over a custom input tensor\n",
    "# Giving that the default input shape is (299,299,3)\n",
    "# Change the input shape\n",
    "# this could also be the output a different Keras model or layer\n",
    "print(K.image_data_format())\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(139, 139, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_3\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_4\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_5\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_3\n",
      "11 conv2d_6\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_7\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_4\n",
      "18 conv2d_11\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_9\n",
      "22 conv2d_12\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_8\n",
      "29 conv2d_10\n",
      "30 conv2d_13\n",
      "31 conv2d_14\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_18\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_16\n",
      "45 conv2d_19\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_15\n",
      "52 conv2d_17\n",
      "53 conv2d_20\n",
      "54 conv2d_21\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_25\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_23\n",
      "68 conv2d_26\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_22\n",
      "75 conv2d_24\n",
      "76 conv2d_27\n",
      "77 conv2d_28\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_30\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_31\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_29\n",
      "94 conv2d_32\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_5\n",
      "100 mixed3\n",
      "101 conv2d_37\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_38\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_34\n",
      "108 conv2d_39\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_35\n",
      "114 conv2d_40\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_33\n",
      "121 conv2d_36\n",
      "122 conv2d_41\n",
      "123 conv2d_42\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_47\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_48\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_44\n",
      "140 conv2d_49\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_45\n",
      "146 conv2d_50\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_43\n",
      "153 conv2d_46\n",
      "154 conv2d_51\n",
      "155 conv2d_52\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_57\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_58\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_54\n",
      "172 conv2d_59\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_55\n",
      "178 conv2d_60\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_53\n",
      "185 conv2d_56\n",
      "186 conv2d_61\n",
      "187 conv2d_62\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_67\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_68\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_64\n",
      "204 conv2d_69\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_65\n",
      "210 conv2d_70\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_63\n",
      "217 conv2d_66\n",
      "218 conv2d_71\n",
      "219 conv2d_72\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_75\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_76\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_73\n",
      "236 conv2d_77\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_74\n",
      "242 conv2d_78\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_6\n",
      "248 mixed8\n",
      "249 conv2d_83\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_80\n",
      "253 conv2d_84\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_81\n",
      "259 conv2d_82\n",
      "260 conv2d_85\n",
      "261 conv2d_86\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_79\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_87\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_92\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_89\n",
      "284 conv2d_93\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_90\n",
      "290 conv2d_91\n",
      "291 conv2d_94\n",
      "292 conv2d_95\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_88\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_96\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 10 classes\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze the required layers\n",
    "In Keras, each layer has a parameter called “trainable”. For freezing the weights of a particular layer, we should set this parameter to False, indicating that this layer should not be trained. That’s it! We go over each layer and select which layers we want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 139, 139, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 69, 69, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 69, 69, 32)   96          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 69, 69, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 67, 67, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 67, 67, 32)   96          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 67, 67, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 67, 67, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 67, 67, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 67, 67, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 33, 33, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 33, 33, 80)   5120        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 80)   240         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 31, 31, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 31, 31, 192)  576         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 31, 31, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 15, 15, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 64)   12288       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 15, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 48)   9216        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 15, 15, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 15, 15, 48)   144         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 96)   288         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 15, 15, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 15, 15, 192)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 64)   12288       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 15, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 15, 15, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 15, 15, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 15, 64)   192         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 96)   288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 15, 15, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 15, 15, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 15, 15, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 15, 15, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 15, 15, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 15, 15, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 15, 15, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 15, 15, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 15, 15, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 15, 15, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 15, 15, 96)   288         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 15, 15, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 15, 15, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 15, 15, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 15, 15, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 15, 15, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 15, 15, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 15, 15, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 15, 15, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 15, 15, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 15, 15, 96)   288         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 15, 15, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 15, 15, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 15, 15, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 15, 15, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 15, 15, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 15, 15, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 15, 15, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 15, 15, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 15, 15, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 15, 15, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 15, 15, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 15, 15, 48)   144         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 15, 15, 96)   288         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 15, 15, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 15, 15, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 15, 15, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 15, 15, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 15, 15, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 15, 15, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 15, 15, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 15, 15, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 15, 15, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 15, 15, 96)   288         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 15, 15, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 15, 15, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 15, 15, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 15, 15, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 15, 15, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 15, 15, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 15, 15, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 15, 15, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 15, 15, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 15, 15, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 15, 15, 96)   288         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 15, 15, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 96)     82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 7, 7, 384)    1152        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 96)     288         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 7, 7, 384)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 96)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 128)    114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 128)    384         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 192)    172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 192)    172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 192)    576         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 192)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 192)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 160)    179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 160)    480         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 160)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 160)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 192)    215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 192)    215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 192)    576         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 192)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 192)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 160)    179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 160)    480         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 160)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 160)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 192)    215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 192)    576         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 192)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 192)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 7, 7, 192)    258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 7, 7, 192)    258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 7, 7, 192)    576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 7, 7, 192)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 7, 7, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 3, 3, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 3, 3, 320)    960         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 192)    576         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 3, 3, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 448)    1344        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 320)    960         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 192)    576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 448)    1344        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 3, 3, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 3, 3, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 384)    1152        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 320)    960         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 3, 3, 192)    576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 3, 3, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           10250       dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,911,210\n",
      "Trainable params: 2,108,426\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
